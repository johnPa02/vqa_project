{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKvGZVs4kx1e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import h5py\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "TgYTbJ6ulE_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# baseline simple"
      ],
      "metadata": {
        "id": "6U9lvZ129pF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print(\"Loading VGG-19 model...\")\n",
        "# model = models.vgg19(pretrained=True).to(device)\n",
        "# model.eval()\n",
        "\n",
        "# feature_extractor = torch.nn.Sequential(\n",
        "#     model.features,  # Phần CNN\n",
        "#     torch.nn.Flatten(),  # Chuyển tensor về dạng vector\n",
        "#     *list(model.classifier.children())[:6]  # Giữ lại phần đến fc7\n",
        "# ).to(device)"
      ],
      "metadata": {
        "id": "RuFmCz8llYX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline simple\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])"
      ],
      "metadata": {
        "id": "r9wAYCfH90iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# attention"
      ],
      "metadata": {
        "id": "0XOzRUok9s_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    transforms.CenterCrop(448),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "dmePLg10CXqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = models.vgg19(pretrained=True).features.to(device).eval()"
      ],
      "metadata": {
        "id": "yXES6H2bFSFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_list, transform):\n",
        "        self.image_list = image_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_list[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        return self.transform(image)\n"
      ],
      "metadata": {
        "id": "c9ztcSkq68uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RwaNI1RF7wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_json = '/content/cocoqa_data_prepro.json'  # Thay bằng đường dẫn phù hợp\n",
        "image_root = '/content/drive/MyDrive/vqa_data'  # Thư mục gốc chứa ảnh\n",
        "out_name = 'data_img_att.h5'  # Tên file HDF5 đầu ra\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "8VJom-Mr7GqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading JSON file:\", input_json)\n",
        "with open(input_json, 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "train_list = [os.path.join(image_root, im) for im in json_data['unique_img_train']]\n",
        "test_list = [os.path.join(image_root, im) for im in json_data['unique_img_test']]\n"
      ],
      "metadata": {
        "id": "3GWx1mm-7Li0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageDataset(train_list, transform)\n",
        "test_dataset = ImageDataset(test_list, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "vnURPd_Q7PPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_features(dataloader, model):\n",
        "#     \"\"\" Trích xuất feature từ DataLoader \"\"\"\n",
        "#     features = []\n",
        "#     for batch in tqdm(dataloader, desc=\"Processing images\"):\n",
        "#         batch = batch.to(device)\n",
        "#         with torch.no_grad():\n",
        "#             output = model(batch)\n",
        "#         features.append(output.cpu().numpy())  # Chuyển về numpy array\n",
        "\n",
        "#     return np.vstack(features)  # Ghép tất cả các batch lại"
      ],
      "metadata": {
        "id": "Gc9lz3HK7TOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(dataloader, model, h5file, dataset_name):\n",
        "    \"\"\"Trích xuất feature và ghi trực tiếp vào file HDF5\"\"\"\n",
        "    total = len(dataloader.dataset)\n",
        "\n",
        "    # Lấy shape feature mẫu\n",
        "    with torch.no_grad():\n",
        "        example_feature = model(next(iter(dataloader)).to(device)).detach().cpu().numpy()\n",
        "    feature_shape = example_feature.shape[1:]  # (C, H, W)\n",
        "\n",
        "    # Tạo dataset trong file HDF5\n",
        "    dset = h5file.create_dataset(\n",
        "        dataset_name, shape=(total, *feature_shape), dtype='float32'\n",
        "    )\n",
        "\n",
        "    idx = 0\n",
        "    for batch in tqdm(dataloader, desc=f\"Processing {dataset_name}\"):\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(batch).detach().cpu().numpy()\n",
        "\n",
        "        bsize = output.shape[0]\n",
        "        dset[idx:idx + bsize] = output\n",
        "        idx += bsize\n"
      ],
      "metadata": {
        "id": "waow5XkqHRic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Extracting training image features...\")\n",
        "# feat_train = extract_features(train_loader, vgg)\n",
        "\n",
        "# print(\"Extracting testing image features...\")\n",
        "# feat_test = extract_features(test_loader, vgg)\n",
        "\n",
        "# print(f\"Saving extracted features to {out_name}...\")\n",
        "# with h5py.File(out_name, \"w\") as f:\n",
        "#     f.create_dataset(\"images_train\", data=feat_train)\n",
        "#     f.create_dataset(\"images_test\", data=feat_test)\n",
        "\n",
        "# print(\"Feature extraction completed successfully!\")"
      ],
      "metadata": {
        "id": "MVsV7Ess7Vo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(out_name, \"w\") as f:\n",
        "    extract_features(train_loader, vgg, f, \"images_train\")\n",
        "    extract_features(test_loader, vgg, f, \"images_test\")"
      ],
      "metadata": {
        "id": "8eq1XEtSJMSO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}