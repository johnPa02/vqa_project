{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10949220,"sourceType":"datasetVersion","datasetId":6810608},{"sourceId":10976729,"sourceType":"datasetVersion","datasetId":6830438},{"sourceId":10988475,"sourceType":"datasetVersion","datasetId":6839269}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"Using CPU.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sudo apt update\n!sudo apt install -y pciutils\n!curl -fsSL https://ollama.com/install.sh | sh\n!pip install ollama","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make Ollama run like a service\nimport time\nimport threading\nimport subprocess\n\ndef ollama_service_start():\n  subprocess.Popen(['ollama', 'serve'])\n\nthread = threading.Thread(target=ollama_service_start)\nthread.start()\ntime.sleep(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ollama pull deepseek-r1","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ollama list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEEPSEEK_MODEL = 'deepseek-r1:latest'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef remove_think_tag(content):\n  pattern = \"<think>(.|\\s)*?<\\/think>\"\n  return re.sub(pattern, \"\", content).strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ollama\ndef classify_vehicle_related(text):\n    prompt = f\"\"\"\n    You are a highly accurate classifier that determines whether a given question-answer pair is related to vehicles or not.\n\n    A vehicle is any means of transport, including but not limited to: cars, bicycles, motorcycles, trucks, buses, trains, airplanes, and boats.\n\n    Please analyze the following input and respond with only \"Yes\" if it is related to vehicles, and \"No\" otherwise.\n    \n    Input: \"{text}\"\n    Output:\n    \"\"\"\n\n    response = ollama.chat(model=DEEPSEEK_MODEL, messages=[{\"role\": \"user\", \"content\": prompt}])\n    return response[\"message\"][\"content\"].strip()\n\n# Test\ntext = \"what is the color of the sign ? - red\"\nresult = classify_vehicle_related(text)\nprint(result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/input/test-raw-data/cocoqa_raw_test.json\", 'r') as f:\n    train_data = json.load(f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\n\nBATCH_SIZE = 50\nfiltered_data_path = \"/kaggle/input/checkpoint/vehicle_raw_test.json\"\nSAVE_PATH = \"/kaggle/working/filtered_data_test.json\"\n\nfiltered_data = []\n\nif os.path.exists(filtered_data_path):\n    with open(filtered_data_path, \"r\") as f:\n        try:\n            filtered_data = json.load(f)\n        except json.JSONDecodeError:\n            filtered_data = []\n\nq = \"what are there coming down the street to a green light ?\"\nstart_idx = next((i + 1 for i, item in enumerate(train_data) \n                  if item['question'] == q), -1)\n\nprint(f'continue to classify questions from index {start_idx}')\nfor idx, item in enumerate(train_data, start=1):\n    qa_pair = f\"{idx}. {item['question']} - {item['ans']}\"\n    result = remove_think_tag(classify_vehicle_related(qa_pair))\n    print(f\"{qa_pair} : {result}\")\n\n    if \"Yes\" not in result:\n        continue\n\n    filtered_data.append(item)\n\n    # Cứ sau mỗi BATCH_SIZE lần thì lưu vào file\n    if idx % BATCH_SIZE == 0:\n        with open(SAVE_PATH, \"w\") as f:\n            json.dump(filtered_data, f, indent=4)\n        print(f\"Saved {len(filtered_data)} samples at {SAVE_PATH}\")\n\nwith open(SAVE_PATH, \"w\") as f:\n    json.dump(filtered_data, f, indent=4)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-11T07:15:53.590Z"}},"outputs":[],"execution_count":null}]}